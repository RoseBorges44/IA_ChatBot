{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aaae1980",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install datasets --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a01a266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "# Configura√ß√£o do dispositivo\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Usando dispositivo: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dc9334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 1. PREPROCESSAMENTO DOS DADOS\n",
    "# ============================\n",
    "\n",
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        self.word2index = {\"<PAD>\": 0, \"<SOS>\": 1, \"<EOS>\": 2, \"<UNK>\": 3}\n",
    "        self.index2word = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\", 3: \"<UNK>\"}\n",
    "        self.word_count = {}\n",
    "        self.n_words = 4\n",
    "        \n",
    "    def add_sentence(self, sentence):\n",
    "        for word in sentence.split():\n",
    "            self.add_word(word)\n",
    "    \n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.word_count[word] = 1\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word_count[word] += 1\n",
    "\n",
    "# def preprocess_text(text):\n",
    "#     \"\"\"Preprocessa o texto removendo caracteres especiais e normalizando\"\"\"\n",
    "#     text = text.lower()\n",
    "#     text = re.sub(r'[^\\w\\s]', '', text)  # Remove pontua√ß√£o\n",
    "#     text = re.sub(r'\\s+', ' ', text)     # Remove espa√ßos extras\n",
    "#     return text.strip()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Preprocessa o texto removendo caracteres especiais e normalizando.\"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9034e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dailydialog_data():\n",
    "    try:\n",
    "        from datasets import load_dataset\n",
    "    except ImportError:\n",
    "        import os\n",
    "        os.system(\"pip install datasets\")\n",
    "        from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27674667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dailydialog_data():\n",
    "    \"\"\"\n",
    "    Carrega dados do DailyDialog, processa e extrai pares de pergunta-resposta.\n",
    "    \"\"\"\n",
    "    ds = load_dataset(\"roskoN/dailydialog\", revision=\"refs/convert/parquet\")\n",
    "    pairs = []\n",
    "    \n",
    "    # O nome correto da coluna, 'utterances', agora √© usado aqui.\n",
    "    nome_da_coluna = 'utterances'\n",
    "    \n",
    "    for split in (\"train\", \"validation\", \"test\"):\n",
    "        for turns in ds[split][nome_da_coluna]:\n",
    "            turns = [preprocess_text(t) for t in turns]\n",
    "            for i in range(len(turns) - 1):\n",
    "                question = turns[i]\n",
    "                answer = turns[i + 1]\n",
    "                if len(question.split()) <= 20 and len(answer.split()) <= 15:\n",
    "                    pairs.append((question, answer))\n",
    "    return pairs\n",
    "\n",
    "    \n",
    "def prepare_data(pairs, max_length=20):\n",
    "    \"\"\"Prepara os dados para treinamento\"\"\"\n",
    "    vocabulary = Vocabulary()\n",
    "    \n",
    "    # Filtra pares por comprimento e adiciona ao vocabul√°rio\n",
    "    filtered_pairs = []\n",
    "    for question, answer in pairs:\n",
    "        if len(question.split()) <= max_length and len(answer.split()) <= max_length:\n",
    "            vocabulary.add_sentence(question)\n",
    "            vocabulary.add_sentence(answer)\n",
    "            filtered_pairs.append((question, answer))\n",
    "    \n",
    "    return filtered_pairs, vocabulary\n",
    "\n",
    "def sentence_to_indexes(sentence, vocabulary):\n",
    "    \"\"\"Converte uma senten√ßa para √≠ndices\"\"\"\n",
    "    indexes = []\n",
    "    for word in sentence.split():\n",
    "        if word in vocabulary.word2index:\n",
    "            indexes.append(vocabulary.word2index[word])\n",
    "        else:\n",
    "            indexes.append(vocabulary.word2index[\"<UNK>\"])\n",
    "    return indexes\n",
    "\n",
    "def pad_sequences(sequences, max_length, pad_token=0):\n",
    "    \"\"\"Adiciona padding √†s sequ√™ncias\"\"\"\n",
    "    padded = []\n",
    "    for seq in sequences:\n",
    "        if len(seq) < max_length:\n",
    "            padded.append(seq + [pad_token] * (max_length - len(seq)))\n",
    "        else:\n",
    "            padded.append(seq[:max_length])\n",
    "    return padded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8218339",
   "metadata": {},
   "outputs": [],
   "source": [
    "#============================\n",
    "# 2. DATASET \n",
    "# ============================\n",
    "\n",
    "class ChatDataset(Dataset):\n",
    "    def __init__(self, pairs, vocabulary, max_length=20):\n",
    "        self.pairs = pairs\n",
    "        self.vocabulary = vocabulary\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        question, answer = self.pairs[idx]\n",
    "        \n",
    "        # Converte para √≠ndices\n",
    "        question_indexes = sentence_to_indexes(question, self.vocabulary)\n",
    "        answer_indexes = sentence_to_indexes(answer, self.vocabulary)\n",
    "        \n",
    "        # Adiciona tokens especiais\n",
    "        question_indexes = [self.vocabulary.word2index[\"<SOS>\"]] + question_indexes + [self.vocabulary.word2index[\"<EOS>\"]]\n",
    "        answer_indexes   = [self.vocabulary.word2index[\"<SOS>\"]] + answer_indexes   + [self.vocabulary.word2index[\"<EOS>\"]]\n",
    "        \n",
    "        # Padding\n",
    "        question_padded = question_indexes + [0] * (self.max_length + 2 - len(question_indexes))\n",
    "        answer_padded = answer_indexes + [0] * (self.max_length + 2 - len(answer_indexes))\n",
    "        \n",
    "        # Trunca se necess√°rio\n",
    "        question_padded = question_padded[:self.max_length + 2]\n",
    "        answer_padded = answer_padded[:self.max_length + 2]\n",
    "        \n",
    "        return {\n",
    "            'question': torch.tensor(question_padded, dtype=torch.long),\n",
    "            'answer': torch.tensor(answer_padded, dtype=torch.long),\n",
    "            'question_length': torch.tensor(len(question_indexes), dtype=torch.long),\n",
    "            'answer_length': torch.tensor(len(answer_indexes), dtype=torch.long)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0739a8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 3. MODELO SEQ2SEQ COM ATEN√á√ÉO\n",
    "# ============================\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, embedding_dim, n_layers=2, dropout=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size, n_layers, \n",
    "                           dropout=dropout, bidirectional=True, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input_seq, input_lengths):\n",
    "        embedded = self.dropout(self.embedding(input_seq))\n",
    "\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(\n",
    "            embedded, input_lengths, batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        packed_outputs, (hidden, cell) = self.lstm(packed)\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs, batch_first=True)\n",
    "\n",
    "        # Combina as duas dire√ß√µes na dimens√£o de features (j√° era feito):\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, :, self.hidden_size:]\n",
    "\n",
    "        # ===== NOVO: combina tamb√©m hidden e cell =====\n",
    "        # hidden / cell:  (n_layers*2, batch, hidden_size)\n",
    "        hidden = hidden.view(self.n_layers, 2, -1, self.hidden_size).sum(1)\n",
    "        cell   = cell.view(self.n_layers, 2, -1, self.hidden_size).sum(1)\n",
    "        # Agora: (n_layers, batch, hidden_size)\n",
    "\n",
    "        return outputs, hidden, cell\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attn = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.v = nn.Linear(hidden_size, 1, bias=False)\n",
    "        \n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        # hidden: (batch_size, hidden_size)\n",
    "        # encoder_outputs: (batch_size, seq_len, hidden_size)\n",
    "        \n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        seq_len = encoder_outputs.size(1)\n",
    "        \n",
    "        # Repeat decoder hidden state seq_len times\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, seq_len, 1)\n",
    "        \n",
    "        # Calculate attention weights\n",
    "        energy = torch.tanh(self.attn(torch.cat([hidden, encoder_outputs], dim=2)))\n",
    "        attention_weights = self.v(energy).squeeze(2)\n",
    "        \n",
    "        # Apply softmax to get attention weights\n",
    "        attention_weights = F.softmax(attention_weights, dim=1)\n",
    "        \n",
    "        # Apply attention weights to encoder outputs\n",
    "        context = torch.bmm(attention_weights.unsqueeze(1), encoder_outputs)\n",
    "        \n",
    "        return context.squeeze(1), attention_weights\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, embedding_dim, n_layers=2, dropout=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim + hidden_size * 2, hidden_size, num_layers=n_layers, dropout=dropout, batch_first=True)\n",
    "        self.attention = Attention(hidden_size)\n",
    "        self.out = nn.Linear(hidden_size * 2, vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input_token, hidden, cell, encoder_outputs):\n",
    "        # input_token: (batch_size, 1)\n",
    "        # hidden: (n_layers, batch_size, hidden_size)\n",
    "        # encoder_outputs: (batch_size, seq_len, hidden_size)\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(input_token))\n",
    "        \n",
    "        # Get attention context\n",
    "        last_hidden = hidden[-1]  # Use last layer hidden state\n",
    "        context, attention_weights = self.attention(last_hidden, encoder_outputs)\n",
    "        \n",
    "        # Combine embedding with context\n",
    "        lstm_input = torch.cat([embedded, context.unsqueeze(1)], dim=2)\n",
    "        \n",
    "        # Forward through LSTM\n",
    "        lstm_output, (hidden, cell) = self.lstm(lstm_input, (hidden, cell))\n",
    "        \n",
    "        # Combine LSTM output with context for prediction\n",
    "        output = torch.cat([lstm_output.squeeze(1), context], dim=1)\n",
    "        output = self.out(output)\n",
    "        \n",
    "        return output, hidden, cell, attention_weights\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, src, src_len, trg, teacher_forcing_ratio=0.5):\n",
    "        batch_size = src.size(0)\n",
    "        trg_len = trg.size(1)\n",
    "        trg_vocab_size = self.decoder.vocab_size\n",
    "        \n",
    "        # Tensor to store decoder outputs\n",
    "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        # Encoder\n",
    "        encoder_outputs, hidden, cell = self.encoder(src, src_len)\n",
    "        \n",
    "        # First input to decoder is SOS token\n",
    "        input_token = trg[:, 0].unsqueeze(1)\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            # Forward through decoder\n",
    "            output, hidden, cell, attention = self.decoder(input_token, hidden, cell, encoder_outputs)\n",
    "            \n",
    "            # Store output\n",
    "            outputs[:, t] = output\n",
    "            \n",
    "            # Decide if we use teacher forcing\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            # Get the highest predicted token\n",
    "            top1 = output.argmax(1)\n",
    "            \n",
    "            # Update input token\n",
    "            input_token = trg[:, t].unsqueeze(1) if teacher_force else top1.unsqueeze(1)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c59a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 4. TREINAMENTO\n",
    "# ============================\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in tqdm(dataloader, desc=\"Treinando\"):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        src = batch['question'].to(device)\n",
    "        src_len = batch['question_length'].to(device)\n",
    "        trg = batch['answer'].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(src, src_len, trg)\n",
    "        \n",
    "        # Calculate loss\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[:, 1:].reshape(-1, output_dim)\n",
    "        trg = trg[:, 1:].reshape(-1)\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Clip gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            src = batch['question'].to(device)\n",
    "            src_len = batch['question_length'].to(device)\n",
    "            trg = batch['answer'].to(device)\n",
    "            \n",
    "            # Forward pass with no teacher forcing\n",
    "            output = model(src, src_len, trg, teacher_forcing_ratio=0)\n",
    "            \n",
    "            # Calculate loss\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[:, 1:].reshape(-1, output_dim)\n",
    "            trg = trg[:, 1:].reshape(-1)\n",
    "            \n",
    "            loss = criterion(output, trg)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs, device):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0)  # Ignore padding token\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        \n",
    "        # Training\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # Validation\n",
    "        val_loss = evaluate(model, val_loader, criterion, device)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                'val_loss': val_loss,\n",
    "            }, 'best_chatbot_model.pth')\n",
    "            print(\"Modelo salvo!\")\n",
    "    \n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eebf13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 5. INFER√äNCIA\n",
    "# ============================\n",
    "\n",
    "def respond(model, question, vocabulary, device, max_length=20):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Preprocess question\n",
    "        question = preprocess_text(question)\n",
    "        question_indexes = sentence_to_indexes(question, vocabulary)\n",
    "        question_indexes = [vocabulary.word2index[\"<SOS>\"]] + question_indexes + [vocabulary.word2index[\"<EOS>\"]]\n",
    "        \n",
    "        # Convert to tensor\n",
    "        src = torch.tensor(question_indexes, dtype=torch.long).unsqueeze(0).to(device)\n",
    "        src_len = torch.tensor([len(question_indexes)], dtype=torch.long).to(device)\n",
    "        \n",
    "        # Encode\n",
    "        encoder_outputs, hidden, cell = model.encoder(src, src_len)\n",
    "        \n",
    "        # Decode\n",
    "        input_token = torch.tensor([vocabulary.word2index[\"<SOS>\"]], dtype=torch.long).unsqueeze(0).to(device)\n",
    "        response_indexes = []\n",
    "        \n",
    "        for _ in range(max_length):\n",
    "            output, hidden, cell, attention = model.decoder(input_token, hidden, cell, encoder_outputs)\n",
    "            predicted_token = output.argmax(1).item()\n",
    "            \n",
    "            if predicted_token == vocabulary.word2index[\"<EOS>\"]:\n",
    "                break\n",
    "                \n",
    "            response_indexes.append(predicted_token)\n",
    "            input_token = torch.tensor([predicted_token], dtype=torch.long).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Convert back to words\n",
    "        response_words = [vocabulary.index2word[idx] for idx in response_indexes \n",
    "                         if idx in vocabulary.index2word and idx != vocabulary.word2index[\"<PAD>\"]]\n",
    "        \n",
    "        return ' '.join(response_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9a6108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 6. FUN√á√ÉO PRINCIPAL\n",
    "# ============================\n",
    "\n",
    "def main():\n",
    "    # Hiperpar√¢metros\n",
    "    EMBEDDING_DIM = 128\n",
    "    HIDDEN_SIZE = 256\n",
    "    N_LAYERS = 2\n",
    "    DROPOUT = 0.05\n",
    "    BATCH_SIZE = 8\n",
    "    NUM_EPOCHS = 10\n",
    "    MAX_LENGTH = 20\n",
    "    \n",
    "    print(\"Carregando dados...\")\n",
    "    # Carrega dados (usar dataset de exemplo por enquanto)\n",
    "    pairs = load_dailydialog_data()\n",
    "    # üîΩ Limita para 5.000 pares para acelerar treinamento\n",
    "    pairs = pairs[:10000]\n",
    "    print(f\"Carregados {len(pairs)} pares de pergunta-resposta\")\n",
    "    \n",
    "    # Prepara dados\n",
    "    pairs, vocabulary = prepare_data(pairs, MAX_LENGTH)\n",
    "    print(f\"Vocabul√°rio cont√©m {vocabulary.n_words} palavras\")\n",
    "    \n",
    "    # Divide dados\n",
    "    train_pairs, val_pairs = train_test_split(pairs, test_size=0.1, random_state=42)\n",
    "    \n",
    "    # Cria datasets\n",
    "    train_dataset = ChatDataset(train_pairs, vocabulary, MAX_LENGTH)\n",
    "    val_dataset = ChatDataset(val_pairs, vocabulary, MAX_LENGTH)\n",
    "    \n",
    "    # Cria dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    # Cria modelo\n",
    "    encoder = Encoder(vocabulary.n_words, HIDDEN_SIZE, EMBEDDING_DIM, N_LAYERS, DROPOUT)\n",
    "    decoder = Decoder(vocabulary.n_words, HIDDEN_SIZE, EMBEDDING_DIM, N_LAYERS, DROPOUT)\n",
    "    model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "    \n",
    "    print(f\"Modelo criado com {sum(p.numel() for p in model.parameters())} par√¢metros\")\n",
    "    \n",
    "    # Treina modelo\n",
    "    print(\"Iniciando treinamento...\")\n",
    "    train_losses, val_losses = train_model(model, train_loader, val_loader, NUM_EPOCHS, device)\n",
    "    \n",
    "    # Salva vocabul√°rio\n",
    "    with open('vocabulary.pkl', 'wb') as f:\n",
    "        pickle.dump(vocabulary, f)\n",
    "    \n",
    "    # Plota perdas\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig('training_loss.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # Carrega melhor modelo\n",
    "    checkpoint = torch.load('best_chatbot_model.pth')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    # Testa modelo\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"TESTANDO O CHATBOT\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    test_questions = [\n",
    "        \"oi\",\n",
    "        \"como vai\",\n",
    "        \"qual seu nome\",\n",
    "        \"voce gosta de musica\",\n",
    "        \"conte uma piada\",\n",
    "        \"voce e feliz\"\n",
    "    ]\n",
    "    \n",
    "    for question in test_questions:\n",
    "        response = respond(model, question, vocabulary, device)\n",
    "        print(f\"Pergunta: {question}\")\n",
    "        print(f\"Resposta: {response}\")\n",
    "        print(\"-\" * 30)\n",
    "    \n",
    "    return model, vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86bc28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\", 3: \"<UNK>\"}\n",
    "        self.n_words = 4  # Contando os tokens especiais\n",
    "\n",
    "    def add_sentence(self, sentence):\n",
    "        for word in sentence.split():\n",
    "            self.add_word(word)\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d2a0d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando modelo...\n",
      "Modelo carregado com sucesso!\n",
      "Digite 'sair' para terminar a conversa\n",
      "==================================================\n",
      "Chatbot: what you you\n",
      "Chatbot: fine\n",
      "Chatbot: yes i like a\n",
      "Chatbot: i like a a\n",
      "Chatbot: what\n",
      "Chatbot: At√© logo! Foi um prazer conversar com voc√™!\n",
      "Para executar este c√≥digo:\n",
      "1. Descomente 'main()' para treinar o modelo\n",
      "2. Ap√≥s o treinamento, descomente 'interactive_chat()' para usar o chatbot\n",
      "3. Ou execute c√©lulas individuais conforme necess√°rio\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 7. INTERFACE INTERATIVA\n",
    "# ============================\n",
    "\n",
    "def interactive_chat():\n",
    "    \"\"\"Interface interativa para conversar com o chatbot\"\"\"\n",
    "    print(\"Carregando modelo...\")\n",
    "\n",
    "    # Importa load_dataset se necess√°rio\n",
    "    try:\n",
    "        from datasets import load_dataset\n",
    "    except ImportError:\n",
    "        %pip install datasets\n",
    "        from datasets import load_dataset\n",
    "    \n",
    "    # Carrega modelo e vocabul√°rio\n",
    "    try:\n",
    "        with open(r'C:\\Users\\rosej\\OneDrive\\Desktop\\IA - 25\\IA\\Chatbot\\chat\\vocabulary.pkl', 'rb') as f:\n",
    "            vocabulary = pickle.load(f)\n",
    "        \n",
    "        # Recria modelo usando os mesmos hiperpar√¢metros do treinamento\n",
    "        # Use as classes j√° definidas na c√©lula 7 (n√£o redefina!)\n",
    "        encoder = Encoder(vocabulary.n_words, HIDDEN_SIZE, EMBEDDING_DIM, N_LAYERS, DROPOUT)\n",
    "        decoder = Decoder(vocabulary.n_words, HIDDEN_SIZE, EMBEDDING_DIM, N_LAYERS, DROPOUT)\n",
    "        model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "\n",
    "        # Carrega pesos\n",
    "        checkpoint = torch.load(r'C:\\Users\\rosej\\OneDrive\\Desktop\\IA - 25\\IA\\Chatbot\\chat\\best_chatbot_model.pth')\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        print(\"Modelo carregado com sucesso!\")\n",
    "        print(\"Digite 'sair' para terminar a conversa\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        while True:\n",
    "            user_input = input(\"Voc√™: \")\n",
    "            if user_input.lower() == 'sair':\n",
    "                print(\"Chatbot: At√© logo! Foi um prazer conversar com voc√™!\")\n",
    "                break\n",
    "            \n",
    "            response = respond(model, user_input, vocabulary, device)\n",
    "            print(f\"Chatbot: {response}\")\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(\"Modelo n√£o encontrado! Execute o treinamento primeiro.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # print(\"Iniciando o processo de treinamento...\")\n",
    "    # main()\n",
    "    # print(\"Processo finalizado.\")\n",
    "    # Uncomment para treinar o modelo\n",
    "    # main()\n",
    "    \n",
    "    #Uncomment para usar interface interativa\n",
    "    \n",
    "    interactive_chat()\n",
    "    \n",
    "    # Para demo, execute o treinamento\n",
    "    print(\"Para executar este c√≥digo:\")\n",
    "    print(\"1. Descomente 'main()' para treinar o modelo\")\n",
    "    print(\"2. Ap√≥s o treinamento, descomente 'interactive_chat()' para usar o chatbot\")\n",
    "    print(\"3. Ou execute c√©lulas individuais conforme necess√°rio\")\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67eb906",
   "metadata": {},
   "source": [
    "## Teste 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0106bc71",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected 'except' or 'finally' block (2333880912.py, line 209)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[14], line 209\u001b[1;36m\u001b[0m\n\u001b[1;33m    if __name__ == \"__main__\":\u001b[0m\n\u001b[1;37m                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m expected 'except' or 'finally' block\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "import re\n",
    "import random\n",
    "\n",
    "# ============================\n",
    "# 0. CONFIGURA√á√ÉO\n",
    "# ============================\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "# Hiperpar√¢metros (devem ser os mesmos do treinamento)\n",
    "EMBEDDING_DIM = 128\n",
    "HIDDEN_SIZE = 256\n",
    "N_LAYERS = 2\n",
    "DROPOUT = 0.05\n",
    "MAX_LENGTH = 20\n",
    "\n",
    "# ============================\n",
    "# 1. PR√â-PROCESSAMENTO E VOCABUL√ÅRIO\n",
    "# ============================\n",
    "\n",
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        self.word2index = {\"<PAD>\": 0, \"<SOS>\": 1, \"<EOS>\": 2, \"<UNK>\": 3}\n",
    "        self.index2word = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\", 3: \"<UNK>\"}\n",
    "        self.word_count = {}\n",
    "        self.n_words = 4\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Preprocessa o texto removendo caracteres especiais e normalizando.\"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "def sentence_to_indexes(sentence, vocabulary):\n",
    "    \"\"\"Converte uma senten√ßa para √≠ndices.\"\"\"\n",
    "    indexes = []\n",
    "    for word in sentence.split():\n",
    "        if word in vocabulary.word2index:\n",
    "            indexes.append(vocabulary.word2index[word])\n",
    "        else:\n",
    "            indexes.append(vocabulary.word2index[\"<UNK>\"])\n",
    "    return indexes\n",
    "\n",
    "# ============================\n",
    "# 2. MODELO SEQ2SEQ COM ATEN√á√ÉO (ARQUITETURA CORRIGIDA)\n",
    "# ============================\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, embedding_dim, n_layers=2, dropout=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size, n_layers,\n",
    "                           dropout=dropout, bidirectional=True, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input_seq, input_lengths):\n",
    "        embedded = self.dropout(self.embedding(input_seq))\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(\n",
    "            embedded, input_lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        packed_outputs, (hidden, cell) = self.lstm(packed)\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs, batch_first=True)\n",
    "\n",
    "        # Soma as sa√≠das das duas dire√ß√µes (forward e backward)\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, :, self.hidden_size:]\n",
    "\n",
    "        # Combina os hidden e cell states das duas dire√ß√µes\n",
    "        hidden = hidden.view(self.n_layers, 2, -1, self.hidden_size).sum(1)\n",
    "        cell = cell.view(self.n_layers, 2, -1, self.hidden_size).sum(1)\n",
    "\n",
    "        return outputs, hidden, cell\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attn = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.v = nn.Linear(hidden_size, 1, bias=False)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        seq_len = encoder_outputs.size(1)\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, seq_len, 1)\n",
    "        energy = torch.tanh(self.attn(torch.cat([hidden, encoder_outputs], dim=2)))\n",
    "        attention_weights = self.v(energy).squeeze(2)\n",
    "        return F.softmax(attention_weights, dim=1)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, embedding_dim, n_layers=2, dropout=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.attention = Attention(hidden_size)\n",
    "\n",
    "        # CORRE√á√ÉO: A entrada da LSTM deve ser embedding_dim + hidden_size\n",
    "        # Esta era a principal fonte de erro ao carregar o modelo.\n",
    "        self.lstm = nn.LSTM(embedding_dim + hidden_size, hidden_size, n_layers, dropout=dropout, batch_first=True)\n",
    "\n",
    "        self.out = nn.Linear(hidden_size * 2, vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input_token, hidden, cell, encoder_outputs):\n",
    "        embedded = self.dropout(self.embedding(input_token))\n",
    "        \n",
    "        # Usa o √∫ltimo hidden state do decoder para a aten√ß√£o\n",
    "        last_hidden = hidden[-1]\n",
    "        attention_weights = self.attention(last_hidden, encoder_outputs).unsqueeze(1)\n",
    "        \n",
    "        context = torch.bmm(attention_weights, encoder_outputs)\n",
    "        \n",
    "        lstm_input = torch.cat([embedded, context], dim=2)\n",
    "        \n",
    "        lstm_output, (hidden, cell) = self.lstm(lstm_input, (hidden, cell))\n",
    "        \n",
    "        output = torch.cat([lstm_output.squeeze(1), context.squeeze(1)], dim=1)\n",
    "        output = self.out(output)\n",
    "        \n",
    "        return output, hidden, cell, attention_weights\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "    \n",
    "    # O forward completo n√£o √© necess√°rio para a infer√™ncia\n",
    "    def forward(self, src, src_len, trg, teacher_forcing_ratio=0.5):\n",
    "        pass\n",
    "\n",
    "\n",
    "# ============================\n",
    "# 3. FUN√á√ÉO DE INFER√äNCIA\n",
    "# ============================\n",
    "\n",
    "def respond(model, question, vocabulary, device, max_length=20):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        question = preprocess_text(question)\n",
    "        question_indexes = sentence_to_indexes(question, vocabulary)\n",
    "        question_indexes = [vocabulary.word2index[\"<SOS>\"]] + question_indexes + [vocabulary.word2index[\"<EOS>\"]]\n",
    "        \n",
    "        src = torch.tensor(question_indexes, dtype=torch.long).unsqueeze(0).to(device)\n",
    "        src_len = torch.tensor([len(question_indexes)], dtype=torch.long).to(device)\n",
    "        \n",
    "        encoder_outputs, hidden, cell = model.encoder(src, src_len)\n",
    "        \n",
    "        input_token = torch.tensor([[vocabulary.word2index[\"<SOS>\"]]], dtype=torch.long).to(device)\n",
    "        response_indexes = []\n",
    "        \n",
    "        for _ in range(max_length):\n",
    "            output, hidden, cell, attention = model.decoder(input_token, hidden, cell, encoder_outputs)\n",
    "            \n",
    "            predicted_token = output.argmax(1).item()\n",
    "            \n",
    "            if predicted_token == vocabulary.word2index[\"<EOS>\"]:\n",
    "                break\n",
    "            \n",
    "            response_indexes.append(predicted_token)\n",
    "            input_token = torch.tensor([[predicted_token]], dtype=torch.long).to(device)\n",
    "            \n",
    "        response_words = [vocabulary.index2word.get(idx, \"<UNK>\") for idx in response_indexes]\n",
    "        \n",
    "        return ' '.join(response_words)\n",
    "\n",
    "# ============================\n",
    "# 4. EXECU√á√ÉO PRINCIPAL\n",
    "# ============================\n",
    "\n",
    "def interactive_chat():\n",
    "    \"\"\"Interface interativa para conversar com o chatbot.\"\"\"\n",
    "    try:\n",
    "        print(\"Carregando modelo e vocabul√°rio...\")\n",
    "        # Carregue o vocabul√°rio\n",
    "        with open('vocabulary.pkl', 'rb') as f:\n",
    "            vocabulary = pickle.load(f)\n",
    "        \n",
    "        # Recrie o modelo com a arquitetura correta\n",
    "        encoder = Encoder(vocabulary.n_words, HIDDEN_SIZE, EMBEDDING_DIM, N_LAYERS, DROPOUT)\n",
    "        decoder = Decoder(vocabulary.n_words, HIDDEN_SIZE, EMBEDDING_DIM, N_LAYERS, DROPOUT)\n",
    "        model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "        \n",
    "        # Carregue os pesos do modelo treinado\n",
    "        checkpoint = torch.load('best_chatbot_model.pth', map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        print(\"‚úÖ Modelo carregado com sucesso!\")\n",
    "        print(\"üí¨ Digite 'sair' para terminar a conversa.\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        while True:\n",
    "            user_input = input(\"Voc√™: \")\n",
    "            if user_input.lower() == 'sair':\n",
    "                print(\"Chatbot: At√© logo! Foi um prazer conversar com voc√™!\")\n",
    "                break\n",
    "            \n",
    "            response = respond(model, user_input, vocabulary, device)\n",
    "            print(f\"Chatbot: {response}\")\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    interactive_chat()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (novo_chatbot)",
   "language": "python",
   "name": "novo_chatbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
