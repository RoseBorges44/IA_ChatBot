{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aaae1980",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install datasets --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a01a266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "# Configuração do dispositivo\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Usando dispositivo: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dc9334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 1. PREPROCESSAMENTO DOS DADOS\n",
    "# ============================\n",
    "\n",
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        self.word2index = {\"<PAD>\": 0, \"<SOS>\": 1, \"<EOS>\": 2, \"<UNK>\": 3}\n",
    "        self.index2word = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\", 3: \"<UNK>\"}\n",
    "        self.word_count = {}\n",
    "        self.n_words = 4\n",
    "        \n",
    "    def add_sentence(self, sentence):\n",
    "        for word in sentence.split():\n",
    "            self.add_word(word)\n",
    "    \n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.word_count[word] = 1\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word_count[word] += 1\n",
    "\n",
    "# def preprocess_text(text):\n",
    "#     \"\"\"Preprocessa o texto removendo caracteres especiais e normalizando\"\"\"\n",
    "#     text = text.lower()\n",
    "#     text = re.sub(r'[^\\w\\s]', '', text)  # Remove pontuação\n",
    "#     text = re.sub(r'\\s+', ' ', text)     # Remove espaços extras\n",
    "#     return text.strip()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Preprocessa o texto removendo caracteres especiais e normalizando.\"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9034e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dailydialog_data():\n",
    "    try:\n",
    "        from datasets import load_dataset\n",
    "    except ImportError:\n",
    "        import os\n",
    "        os.system(\"pip install datasets\")\n",
    "        from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27674667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dailydialog_data():\n",
    "    \"\"\"\n",
    "    Carrega dados do DailyDialog, processa e extrai pares de pergunta-resposta.\n",
    "    \"\"\"\n",
    "    ds = load_dataset(\"roskoN/dailydialog\", revision=\"refs/convert/parquet\")\n",
    "    pairs = []\n",
    "    \n",
    "    # O nome correto da coluna, 'utterances', agora é usado aqui.\n",
    "    nome_da_coluna = 'utterances'\n",
    "    \n",
    "    for split in (\"train\", \"validation\", \"test\"):\n",
    "        for turns in ds[split][nome_da_coluna]:\n",
    "            turns = [preprocess_text(t) for t in turns]\n",
    "            for i in range(len(turns) - 1):\n",
    "                question = turns[i]\n",
    "                answer = turns[i + 1]\n",
    "                if len(question.split()) <= 20 and len(answer.split()) <= 15:\n",
    "                    pairs.append((question, answer))\n",
    "    return pairs\n",
    "\n",
    "    \n",
    "def prepare_data(pairs, max_length=20):\n",
    "    \"\"\"Prepara os dados para treinamento\"\"\"\n",
    "    vocabulary = Vocabulary()\n",
    "    \n",
    "    # Filtra pares por comprimento e adiciona ao vocabulário\n",
    "    filtered_pairs = []\n",
    "    for question, answer in pairs:\n",
    "        if len(question.split()) <= max_length and len(answer.split()) <= max_length:\n",
    "            vocabulary.add_sentence(question)\n",
    "            vocabulary.add_sentence(answer)\n",
    "            filtered_pairs.append((question, answer))\n",
    "    \n",
    "    return filtered_pairs, vocabulary\n",
    "\n",
    "def sentence_to_indexes(sentence, vocabulary):\n",
    "    \"\"\"Converte uma sentença para índices\"\"\"\n",
    "    indexes = []\n",
    "    for word in sentence.split():\n",
    "        if word in vocabulary.word2index:\n",
    "            indexes.append(vocabulary.word2index[word])\n",
    "        else:\n",
    "            indexes.append(vocabulary.word2index[\"<UNK>\"])\n",
    "    return indexes\n",
    "\n",
    "def pad_sequences(sequences, max_length, pad_token=0):\n",
    "    \"\"\"Adiciona padding às sequências\"\"\"\n",
    "    padded = []\n",
    "    for seq in sequences:\n",
    "        if len(seq) < max_length:\n",
    "            padded.append(seq + [pad_token] * (max_length - len(seq)))\n",
    "        else:\n",
    "            padded.append(seq[:max_length])\n",
    "    return padded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8218339",
   "metadata": {},
   "outputs": [],
   "source": [
    "#============================\n",
    "# 2. DATASET \n",
    "# ============================\n",
    "\n",
    "class ChatDataset(Dataset):\n",
    "    def __init__(self, pairs, vocabulary, max_length=20):\n",
    "        self.pairs = pairs\n",
    "        self.vocabulary = vocabulary\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        question, answer = self.pairs[idx]\n",
    "        \n",
    "        # Converte para índices\n",
    "        question_indexes = sentence_to_indexes(question, self.vocabulary)\n",
    "        answer_indexes = sentence_to_indexes(answer, self.vocabulary)\n",
    "        \n",
    "        # Adiciona tokens especiais\n",
    "        question_indexes = [self.vocabulary.word2index[\"<SOS>\"]] + question_indexes + [self.vocabulary.word2index[\"<EOS>\"]]\n",
    "        answer_indexes   = [self.vocabulary.word2index[\"<SOS>\"]] + answer_indexes   + [self.vocabulary.word2index[\"<EOS>\"]]\n",
    "        \n",
    "        # Padding\n",
    "        question_padded = question_indexes + [0] * (self.max_length + 2 - len(question_indexes))\n",
    "        answer_padded = answer_indexes + [0] * (self.max_length + 2 - len(answer_indexes))\n",
    "        \n",
    "        # Trunca se necessário\n",
    "        question_padded = question_padded[:self.max_length + 2]\n",
    "        answer_padded = answer_padded[:self.max_length + 2]\n",
    "        \n",
    "        return {\n",
    "            'question': torch.tensor(question_padded, dtype=torch.long),\n",
    "            'answer': torch.tensor(answer_padded, dtype=torch.long),\n",
    "            'question_length': torch.tensor(len(question_indexes), dtype=torch.long),\n",
    "            'answer_length': torch.tensor(len(answer_indexes), dtype=torch.long)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0739a8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 3. MODELO SEQ2SEQ COM ATENÇÃO\n",
    "# ============================\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, embedding_dim, n_layers=2, dropout=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size, n_layers, \n",
    "                           dropout=dropout, bidirectional=True, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input_seq, input_lengths):\n",
    "        embedded = self.dropout(self.embedding(input_seq))\n",
    "\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(\n",
    "            embedded, input_lengths, batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        packed_outputs, (hidden, cell) = self.lstm(packed)\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs, batch_first=True)\n",
    "\n",
    "        # Combina as duas direções na dimensão de features (já era feito):\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, :, self.hidden_size:]\n",
    "\n",
    "        # ===== NOVO: combina também hidden e cell =====\n",
    "        # hidden / cell:  (n_layers*2, batch, hidden_size)\n",
    "        hidden = hidden.view(self.n_layers, 2, -1, self.hidden_size).sum(1)\n",
    "        cell   = cell.view(self.n_layers, 2, -1, self.hidden_size).sum(1)\n",
    "        # Agora: (n_layers, batch, hidden_size)\n",
    "\n",
    "        return outputs, hidden, cell\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attn = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.v = nn.Linear(hidden_size, 1, bias=False)\n",
    "        \n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        # hidden: (batch_size, hidden_size)\n",
    "        # encoder_outputs: (batch_size, seq_len, hidden_size)\n",
    "        \n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        seq_len = encoder_outputs.size(1)\n",
    "        \n",
    "        # Repeat decoder hidden state seq_len times\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, seq_len, 1)\n",
    "        \n",
    "        # Calculate attention weights\n",
    "        energy = torch.tanh(self.attn(torch.cat([hidden, encoder_outputs], dim=2)))\n",
    "        attention_weights = self.v(energy).squeeze(2)\n",
    "        \n",
    "        # Apply softmax to get attention weights\n",
    "        attention_weights = F.softmax(attention_weights, dim=1)\n",
    "        \n",
    "        # Apply attention weights to encoder outputs\n",
    "        context = torch.bmm(attention_weights.unsqueeze(1), encoder_outputs)\n",
    "        \n",
    "        return context.squeeze(1), attention_weights\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, embedding_dim, n_layers=2, dropout=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim + hidden_size * 2, hidden_size, num_layers=n_layers, dropout=dropout, batch_first=True)\n",
    "        self.attention = Attention(hidden_size)\n",
    "        self.out = nn.Linear(hidden_size * 2, vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input_token, hidden, cell, encoder_outputs):\n",
    "        # input_token: (batch_size, 1)\n",
    "        # hidden: (n_layers, batch_size, hidden_size)\n",
    "        # encoder_outputs: (batch_size, seq_len, hidden_size)\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(input_token))\n",
    "        \n",
    "        # Get attention context\n",
    "        last_hidden = hidden[-1]  # Use last layer hidden state\n",
    "        context, attention_weights = self.attention(last_hidden, encoder_outputs)\n",
    "        \n",
    "        # Combine embedding with context\n",
    "        lstm_input = torch.cat([embedded, context.unsqueeze(1)], dim=2)\n",
    "        \n",
    "        # Forward through LSTM\n",
    "        lstm_output, (hidden, cell) = self.lstm(lstm_input, (hidden, cell))\n",
    "        \n",
    "        # Combine LSTM output with context for prediction\n",
    "        output = torch.cat([lstm_output.squeeze(1), context], dim=1)\n",
    "        output = self.out(output)\n",
    "        \n",
    "        return output, hidden, cell, attention_weights\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, src, src_len, trg, teacher_forcing_ratio=0.5):\n",
    "        batch_size = src.size(0)\n",
    "        trg_len = trg.size(1)\n",
    "        trg_vocab_size = self.decoder.vocab_size\n",
    "        \n",
    "        # Tensor to store decoder outputs\n",
    "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        # Encoder\n",
    "        encoder_outputs, hidden, cell = self.encoder(src, src_len)\n",
    "        \n",
    "        # First input to decoder is SOS token\n",
    "        input_token = trg[:, 0].unsqueeze(1)\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            # Forward through decoder\n",
    "            output, hidden, cell, attention = self.decoder(input_token, hidden, cell, encoder_outputs)\n",
    "            \n",
    "            # Store output\n",
    "            outputs[:, t] = output\n",
    "            \n",
    "            # Decide if we use teacher forcing\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            # Get the highest predicted token\n",
    "            top1 = output.argmax(1)\n",
    "            \n",
    "            # Update input token\n",
    "            input_token = trg[:, t].unsqueeze(1) if teacher_force else top1.unsqueeze(1)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c59a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 4. TREINAMENTO\n",
    "# ============================\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in tqdm(dataloader, desc=\"Treinando\"):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        src = batch['question'].to(device)\n",
    "        src_len = batch['question_length'].to(device)\n",
    "        trg = batch['answer'].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(src, src_len, trg)\n",
    "        \n",
    "        # Calculate loss\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[:, 1:].reshape(-1, output_dim)\n",
    "        trg = trg[:, 1:].reshape(-1)\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Clip gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            src = batch['question'].to(device)\n",
    "            src_len = batch['question_length'].to(device)\n",
    "            trg = batch['answer'].to(device)\n",
    "            \n",
    "            # Forward pass with no teacher forcing\n",
    "            output = model(src, src_len, trg, teacher_forcing_ratio=0)\n",
    "            \n",
    "            # Calculate loss\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[:, 1:].reshape(-1, output_dim)\n",
    "            trg = trg[:, 1:].reshape(-1)\n",
    "            \n",
    "            loss = criterion(output, trg)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs, device):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0)  # Ignore padding token\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        \n",
    "        # Training\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # Validation\n",
    "        val_loss = evaluate(model, val_loader, criterion, device)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                'val_loss': val_loss,\n",
    "            }, 'best_chatbot_model.pth')\n",
    "            print(\"Modelo salvo!\")\n",
    "    \n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eebf13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 5. INFERÊNCIA\n",
    "# ============================\n",
    "\n",
    "def respond(model, question, vocabulary, device, max_length=20):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Preprocess question\n",
    "        question = preprocess_text(question)\n",
    "        question_indexes = sentence_to_indexes(question, vocabulary)\n",
    "        question_indexes = [vocabulary.word2index[\"<SOS>\"]] + question_indexes + [vocabulary.word2index[\"<EOS>\"]]\n",
    "        \n",
    "        # Convert to tensor\n",
    "        src = torch.tensor(question_indexes, dtype=torch.long).unsqueeze(0).to(device)\n",
    "        src_len = torch.tensor([len(question_indexes)], dtype=torch.long).to(device)\n",
    "        \n",
    "        # Encode\n",
    "        encoder_outputs, hidden, cell = model.encoder(src, src_len)\n",
    "        \n",
    "        # Decode\n",
    "        input_token = torch.tensor([vocabulary.word2index[\"<SOS>\"]], dtype=torch.long).unsqueeze(0).to(device)\n",
    "        response_indexes = []\n",
    "        \n",
    "        for _ in range(max_length):\n",
    "            output, hidden, cell, attention = model.decoder(input_token, hidden, cell, encoder_outputs)\n",
    "            predicted_token = output.argmax(1).item()\n",
    "            \n",
    "            if predicted_token == vocabulary.word2index[\"<EOS>\"]:\n",
    "                break\n",
    "                \n",
    "            response_indexes.append(predicted_token)\n",
    "            input_token = torch.tensor([predicted_token], dtype=torch.long).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Convert back to words\n",
    "        response_words = [vocabulary.index2word[idx] for idx in response_indexes \n",
    "                         if idx in vocabulary.index2word and idx != vocabulary.word2index[\"<PAD>\"]]\n",
    "        \n",
    "        return ' '.join(response_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9a6108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 6. FUNÇÃO PRINCIPAL\n",
    "# ============================\n",
    "\n",
    "def main():\n",
    "    # Hiperparâmetros\n",
    "    EMBEDDING_DIM = 128\n",
    "    HIDDEN_SIZE = 256\n",
    "    N_LAYERS = 2\n",
    "    DROPOUT = 0.05\n",
    "    BATCH_SIZE = 8\n",
    "    NUM_EPOCHS = 10\n",
    "    MAX_LENGTH = 20\n",
    "    \n",
    "    print(\"Carregando dados...\")\n",
    "    # Carrega dados (usar dataset de exemplo por enquanto)\n",
    "    pairs = load_dailydialog_data()\n",
    "    # 🔽 Limita para 5.000 pares para acelerar treinamento\n",
    "    pairs = pairs[:10000]\n",
    "    print(f\"Carregados {len(pairs)} pares de pergunta-resposta\")\n",
    "    \n",
    "    # Prepara dados\n",
    "    pairs, vocabulary = prepare_data(pairs, MAX_LENGTH)\n",
    "    print(f\"Vocabulário contém {vocabulary.n_words} palavras\")\n",
    "    \n",
    "    # Divide dados\n",
    "    train_pairs, val_pairs = train_test_split(pairs, test_size=0.1, random_state=42)\n",
    "    \n",
    "    # Cria datasets\n",
    "    train_dataset = ChatDataset(train_pairs, vocabulary, MAX_LENGTH)\n",
    "    val_dataset = ChatDataset(val_pairs, vocabulary, MAX_LENGTH)\n",
    "    \n",
    "    # Cria dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    # Cria modelo\n",
    "    encoder = Encoder(vocabulary.n_words, HIDDEN_SIZE, EMBEDDING_DIM, N_LAYERS, DROPOUT)\n",
    "    decoder = Decoder(vocabulary.n_words, HIDDEN_SIZE, EMBEDDING_DIM, N_LAYERS, DROPOUT)\n",
    "    model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "    \n",
    "    print(f\"Modelo criado com {sum(p.numel() for p in model.parameters())} parâmetros\")\n",
    "    \n",
    "    # Treina modelo\n",
    "    print(\"Iniciando treinamento...\")\n",
    "    train_losses, val_losses = train_model(model, train_loader, val_loader, NUM_EPOCHS, device)\n",
    "    \n",
    "    # Salva vocabulário\n",
    "    with open('vocabulary.pkl', 'wb') as f:\n",
    "        pickle.dump(vocabulary, f)\n",
    "    \n",
    "    # Plota perdas\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig('training_loss.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # Carrega melhor modelo\n",
    "    checkpoint = torch.load('best_chatbot_model.pth')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    # Testa modelo\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"TESTANDO O CHATBOT\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    test_questions = [\n",
    "        \"oi\",\n",
    "        \"como vai\",\n",
    "        \"qual seu nome\",\n",
    "        \"voce gosta de musica\",\n",
    "        \"conte uma piada\",\n",
    "        \"voce e feliz\"\n",
    "    ]\n",
    "    \n",
    "    for question in test_questions:\n",
    "        response = respond(model, question, vocabulary, device)\n",
    "        print(f\"Pergunta: {question}\")\n",
    "        print(f\"Resposta: {response}\")\n",
    "        print(\"-\" * 30)\n",
    "    \n",
    "    return model, vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86bc28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\", 3: \"<UNK>\"}\n",
    "        self.n_words = 4  # Contando os tokens especiais\n",
    "\n",
    "    def add_sentence(self, sentence):\n",
    "        for word in sentence.split():\n",
    "            self.add_word(word)\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d2a0d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando modelo...\n",
      "Modelo carregado com sucesso!\n",
      "Digite 'sair' para terminar a conversa\n",
      "==================================================\n",
      "Chatbot: what you you\n",
      "Chatbot: fine\n",
      "Chatbot: yes i like a\n",
      "Chatbot: i like a a\n",
      "Chatbot: what\n",
      "Chatbot: Até logo! Foi um prazer conversar com você!\n",
      "Para executar este código:\n",
      "1. Descomente 'main()' para treinar o modelo\n",
      "2. Após o treinamento, descomente 'interactive_chat()' para usar o chatbot\n",
      "3. Ou execute células individuais conforme necessário\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 7. INTERFACE INTERATIVA\n",
    "# ============================\n",
    "\n",
    "def interactive_chat():\n",
    "    \"\"\"Interface interativa para conversar com o chatbot\"\"\"\n",
    "    print(\"Carregando modelo...\")\n",
    "\n",
    "    # Importa load_dataset se necessário\n",
    "    try:\n",
    "        from datasets import load_dataset\n",
    "    except ImportError:\n",
    "        %pip install datasets\n",
    "        from datasets import load_dataset\n",
    "    \n",
    "    # Carrega modelo e vocabulário\n",
    "    try:\n",
    "        with open(r'C:\\Users\\rosej\\OneDrive\\Desktop\\IA - 25\\IA\\Chatbot\\chat\\vocabulary.pkl', 'rb') as f:\n",
    "            vocabulary = pickle.load(f)\n",
    "        \n",
    "        # Recria modelo usando os mesmos hiperparâmetros do treinamento\n",
    "        # Use as classes já definidas na célula 7 (não redefina!)\n",
    "        encoder = Encoder(vocabulary.n_words, HIDDEN_SIZE, EMBEDDING_DIM, N_LAYERS, DROPOUT)\n",
    "        decoder = Decoder(vocabulary.n_words, HIDDEN_SIZE, EMBEDDING_DIM, N_LAYERS, DROPOUT)\n",
    "        model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "\n",
    "        # Carrega pesos\n",
    "        checkpoint = torch.load(r'C:\\Users\\rosej\\OneDrive\\Desktop\\IA - 25\\IA\\Chatbot\\chat\\best_chatbot_model.pth')\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        print(\"Modelo carregado com sucesso!\")\n",
    "        print(\"Digite 'sair' para terminar a conversa\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        while True:\n",
    "            user_input = input(\"Você: \")\n",
    "            if user_input.lower() == 'sair':\n",
    "                print(\"Chatbot: Até logo! Foi um prazer conversar com você!\")\n",
    "                break\n",
    "            \n",
    "            response = respond(model, user_input, vocabulary, device)\n",
    "            print(f\"Chatbot: {response}\")\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(\"Modelo não encontrado! Execute o treinamento primeiro.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # print(\"Iniciando o processo de treinamento...\")\n",
    "    # main()\n",
    "    # print(\"Processo finalizado.\")\n",
    "    # Uncomment para treinar o modelo\n",
    "    # main()\n",
    "    \n",
    "    #Uncomment para usar interface interativa\n",
    "    \n",
    "    interactive_chat()\n",
    "    \n",
    "    # Para demo, execute o treinamento\n",
    "    print(\"Para executar este código:\")\n",
    "    print(\"1. Descomente 'main()' para treinar o modelo\")\n",
    "    print(\"2. Após o treinamento, descomente 'interactive_chat()' para usar o chatbot\")\n",
    "    print(\"3. Ou execute células individuais conforme necessário\")\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67eb906",
   "metadata": {},
   "source": [
    "## Teste 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0106bc71",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected 'except' or 'finally' block (2333880912.py, line 209)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[14], line 209\u001b[1;36m\u001b[0m\n\u001b[1;33m    if __name__ == \"__main__\":\u001b[0m\n\u001b[1;37m                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m expected 'except' or 'finally' block\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "import re\n",
    "import random\n",
    "\n",
    "# ============================\n",
    "# 0. CONFIGURAÇÃO\n",
    "# ============================\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "# Hiperparâmetros (devem ser os mesmos do treinamento)\n",
    "EMBEDDING_DIM = 128\n",
    "HIDDEN_SIZE = 256\n",
    "N_LAYERS = 2\n",
    "DROPOUT = 0.05\n",
    "MAX_LENGTH = 20\n",
    "\n",
    "# ============================\n",
    "# 1. PRÉ-PROCESSAMENTO E VOCABULÁRIO\n",
    "# ============================\n",
    "\n",
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        self.word2index = {\"<PAD>\": 0, \"<SOS>\": 1, \"<EOS>\": 2, \"<UNK>\": 3}\n",
    "        self.index2word = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\", 3: \"<UNK>\"}\n",
    "        self.word_count = {}\n",
    "        self.n_words = 4\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Preprocessa o texto removendo caracteres especiais e normalizando.\"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "def sentence_to_indexes(sentence, vocabulary):\n",
    "    \"\"\"Converte uma sentença para índices.\"\"\"\n",
    "    indexes = []\n",
    "    for word in sentence.split():\n",
    "        if word in vocabulary.word2index:\n",
    "            indexes.append(vocabulary.word2index[word])\n",
    "        else:\n",
    "            indexes.append(vocabulary.word2index[\"<UNK>\"])\n",
    "    return indexes\n",
    "\n",
    "# ============================\n",
    "# 2. MODELO SEQ2SEQ COM ATENÇÃO (ARQUITETURA CORRIGIDA)\n",
    "# ============================\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, embedding_dim, n_layers=2, dropout=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size, n_layers,\n",
    "                           dropout=dropout, bidirectional=True, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input_seq, input_lengths):\n",
    "        embedded = self.dropout(self.embedding(input_seq))\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(\n",
    "            embedded, input_lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        packed_outputs, (hidden, cell) = self.lstm(packed)\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs, batch_first=True)\n",
    "\n",
    "        # Soma as saídas das duas direções (forward e backward)\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, :, self.hidden_size:]\n",
    "\n",
    "        # Combina os hidden e cell states das duas direções\n",
    "        hidden = hidden.view(self.n_layers, 2, -1, self.hidden_size).sum(1)\n",
    "        cell = cell.view(self.n_layers, 2, -1, self.hidden_size).sum(1)\n",
    "\n",
    "        return outputs, hidden, cell\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attn = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.v = nn.Linear(hidden_size, 1, bias=False)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        seq_len = encoder_outputs.size(1)\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, seq_len, 1)\n",
    "        energy = torch.tanh(self.attn(torch.cat([hidden, encoder_outputs], dim=2)))\n",
    "        attention_weights = self.v(energy).squeeze(2)\n",
    "        return F.softmax(attention_weights, dim=1)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, embedding_dim, n_layers=2, dropout=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.attention = Attention(hidden_size)\n",
    "\n",
    "        # CORREÇÃO: A entrada da LSTM deve ser embedding_dim + hidden_size\n",
    "        # Esta era a principal fonte de erro ao carregar o modelo.\n",
    "        self.lstm = nn.LSTM(embedding_dim + hidden_size, hidden_size, n_layers, dropout=dropout, batch_first=True)\n",
    "\n",
    "        self.out = nn.Linear(hidden_size * 2, vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input_token, hidden, cell, encoder_outputs):\n",
    "        embedded = self.dropout(self.embedding(input_token))\n",
    "        \n",
    "        # Usa o último hidden state do decoder para a atenção\n",
    "        last_hidden = hidden[-1]\n",
    "        attention_weights = self.attention(last_hidden, encoder_outputs).unsqueeze(1)\n",
    "        \n",
    "        context = torch.bmm(attention_weights, encoder_outputs)\n",
    "        \n",
    "        lstm_input = torch.cat([embedded, context], dim=2)\n",
    "        \n",
    "        lstm_output, (hidden, cell) = self.lstm(lstm_input, (hidden, cell))\n",
    "        \n",
    "        output = torch.cat([lstm_output.squeeze(1), context.squeeze(1)], dim=1)\n",
    "        output = self.out(output)\n",
    "        \n",
    "        return output, hidden, cell, attention_weights\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "    \n",
    "    # O forward completo não é necessário para a inferência\n",
    "    def forward(self, src, src_len, trg, teacher_forcing_ratio=0.5):\n",
    "        pass\n",
    "\n",
    "\n",
    "# ============================\n",
    "# 3. FUNÇÃO DE INFERÊNCIA\n",
    "# ============================\n",
    "\n",
    "def respond(model, question, vocabulary, device, max_length=20):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        question = preprocess_text(question)\n",
    "        question_indexes = sentence_to_indexes(question, vocabulary)\n",
    "        question_indexes = [vocabulary.word2index[\"<SOS>\"]] + question_indexes + [vocabulary.word2index[\"<EOS>\"]]\n",
    "        \n",
    "        src = torch.tensor(question_indexes, dtype=torch.long).unsqueeze(0).to(device)\n",
    "        src_len = torch.tensor([len(question_indexes)], dtype=torch.long).to(device)\n",
    "        \n",
    "        encoder_outputs, hidden, cell = model.encoder(src, src_len)\n",
    "        \n",
    "        input_token = torch.tensor([[vocabulary.word2index[\"<SOS>\"]]], dtype=torch.long).to(device)\n",
    "        response_indexes = []\n",
    "        \n",
    "        for _ in range(max_length):\n",
    "            output, hidden, cell, attention = model.decoder(input_token, hidden, cell, encoder_outputs)\n",
    "            \n",
    "            predicted_token = output.argmax(1).item()\n",
    "            \n",
    "            if predicted_token == vocabulary.word2index[\"<EOS>\"]:\n",
    "                break\n",
    "            \n",
    "            response_indexes.append(predicted_token)\n",
    "            input_token = torch.tensor([[predicted_token]], dtype=torch.long).to(device)\n",
    "            \n",
    "        response_words = [vocabulary.index2word.get(idx, \"<UNK>\") for idx in response_indexes]\n",
    "        \n",
    "        return ' '.join(response_words)\n",
    "\n",
    "# ============================\n",
    "# 4. EXECUÇÃO PRINCIPAL\n",
    "# ============================\n",
    "\n",
    "def interactive_chat():\n",
    "    \"\"\"Interface interativa para conversar com o chatbot.\"\"\"\n",
    "    try:\n",
    "        print(\"Carregando modelo e vocabulário...\")\n",
    "        # Carregue o vocabulário\n",
    "        with open('vocabulary.pkl', 'rb') as f:\n",
    "            vocabulary = pickle.load(f)\n",
    "        \n",
    "        # Recrie o modelo com a arquitetura correta\n",
    "        encoder = Encoder(vocabulary.n_words, HIDDEN_SIZE, EMBEDDING_DIM, N_LAYERS, DROPOUT)\n",
    "        decoder = Decoder(vocabulary.n_words, HIDDEN_SIZE, EMBEDDING_DIM, N_LAYERS, DROPOUT)\n",
    "        model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "        \n",
    "        # Carregue os pesos do modelo treinado\n",
    "        checkpoint = torch.load('best_chatbot_model.pth', map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        print(\"✅ Modelo carregado com sucesso!\")\n",
    "        print(\"💬 Digite 'sair' para terminar a conversa.\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        while True:\n",
    "            user_input = input(\"Você: \")\n",
    "            if user_input.lower() == 'sair':\n",
    "                print(\"Chatbot: Até logo! Foi um prazer conversar com você!\")\n",
    "                break\n",
    "            \n",
    "            response = respond(model, user_input, vocabulary, device)\n",
    "            print(f\"Chatbot: {response}\")\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    interactive_chat()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (novo_chatbot)",
   "language": "python",
   "name": "novo_chatbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
